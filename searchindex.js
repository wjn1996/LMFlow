Search.setIndex({"docnames": ["about/authors", "about/changelog", "about/index", "api/_autosummary/lmflow.args", "autoapi/index", "autoapi/lmflow/args/index", "autoapi/lmflow/datasets/dataset/index", "autoapi/lmflow/datasets/index", "autoapi/lmflow/index", "autoapi/lmflow/models/auto_model/index", "autoapi/lmflow/models/base_model/index", "autoapi/lmflow/models/decoder_model/index", "autoapi/lmflow/models/hf_decoder_model/index", "autoapi/lmflow/models/index", "autoapi/lmflow/models/interfaces/index", "autoapi/lmflow/models/interfaces/tunable/index", "autoapi/lmflow/pipeline/auto_pipeline/index", "autoapi/lmflow/pipeline/base_pipeline/index", "autoapi/lmflow/pipeline/base_tuner/index", "autoapi/lmflow/pipeline/evaluator/index", "autoapi/lmflow/pipeline/finetuner/index", "autoapi/lmflow/pipeline/index", "autoapi/lmflow/pipeline/inferencer/index", "autoapi/lmflow/utils/data_utils/index", "autoapi/lmflow/utils/index", "autoapi/lmflow/version/index", "documentation/data", "documentation/index", "documentation/infer", "documentation/model", "documentation/tuning", "examples/DATASETS", "examples/index", "examples/medical_finetune", "index"], "filenames": ["about/authors.md", "about/changelog.md", "about/index.md", "api/_autosummary/lmflow.args.rst", "autoapi/index.rst", "autoapi/lmflow/args/index.rst", "autoapi/lmflow/datasets/dataset/index.rst", "autoapi/lmflow/datasets/index.rst", "autoapi/lmflow/index.rst", "autoapi/lmflow/models/auto_model/index.rst", "autoapi/lmflow/models/base_model/index.rst", "autoapi/lmflow/models/decoder_model/index.rst", "autoapi/lmflow/models/hf_decoder_model/index.rst", "autoapi/lmflow/models/index.rst", "autoapi/lmflow/models/interfaces/index.rst", "autoapi/lmflow/models/interfaces/tunable/index.rst", "autoapi/lmflow/pipeline/auto_pipeline/index.rst", "autoapi/lmflow/pipeline/base_pipeline/index.rst", "autoapi/lmflow/pipeline/base_tuner/index.rst", "autoapi/lmflow/pipeline/evaluator/index.rst", "autoapi/lmflow/pipeline/finetuner/index.rst", "autoapi/lmflow/pipeline/index.rst", "autoapi/lmflow/pipeline/inferencer/index.rst", "autoapi/lmflow/utils/data_utils/index.rst", "autoapi/lmflow/utils/index.rst", "autoapi/lmflow/version/index.rst", "documentation/data.md", "documentation/index.md", "documentation/infer.md", "documentation/model.md", "documentation/tuning.md", "examples/DATASETS.md", "examples/index.md", "examples/medical_finetune.md", "index.md"], "titles": ["Contributors", "Changelog", "About", "lmflow.args", "API Reference", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.args</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets.dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.auto_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.base_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.hf_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces.tunable</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.auto_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_tuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.evaluator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.finetuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.inferencer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.data_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.version</span></code>", "Data", "Documentation", "Inference", "Model", "Fine-tuning", "Dataset", "Examples", "Finetune", "LMFlow"], "terms": {"shizh": [0, 34], "diao": [0, 34], "rui": [0, 34], "pan": [0, 34], "hanz": [0, 34], "dong": [0, 34], "ka": 0, "shun": 0, "shum": [0, 34], "jipeng": [0, 34], "zhang": [0, 34], "wei": [0, 34], "xiong": [0, 34], "tong": [0, 34], "The": [1, 5, 6, 7, 11, 12, 16, 19, 20, 22, 23, 31, 34], "first": 1, "public": 1, "task": [1, 12], "tune": [1, 12, 18, 20, 33], "instruct": 1, "user": [1, 31, 34], "defin": [1, 3, 5, 6, 7, 31], "dataset": [1, 3, 4, 5, 8, 12, 18, 19, 20, 22, 23, 32, 33, 34], "A": [1, 6, 11, 12, 18, 23], "simpl": 1, "extens": [1, 34], "api": [1, 34], "develop": 1, "effici": [1, 34], "finetun": [1, 4, 8, 21, 31, 34], "lora": [1, 12, 34], "simplifi": [1, 19, 20, 22, 34], "model": [1, 3, 4, 5, 8, 18, 19, 20, 22, 31, 33, 34], "infer": [1, 12, 19, 22, 31, 34], "framework": 1, "changelog": [2, 34], "version": [2, 3, 4, 5, 8], "0": [2, 8, 22, 25, 34], "1": [2, 4, 5, 6, 8, 25, 31, 33, 34], "mar": 2, "28": [2, 34], "2023": [2, 34], "contributor": [2, 34], "thi": [3, 4, 5, 6, 7, 11, 12, 23, 31, 34], "script": [3, 5, 33], "dataclass": [3, 5], "modelargu": [3, 5, 19, 20, 22, 33], "datasetargu": [3, 5, 6, 19, 20, 22, 33], "contain": [3, 4, 5, 6, 11, 19, 20, 22, 31], "argument": [3, 5, 6, 7, 12, 19, 20, 22, 23, 33], "us": [3, 5, 10, 11, 12, 15, 17, 19, 23, 31, 32, 34], "train": [3, 5, 12, 20, 23, 31, 34], "It": [3, 5, 12, 19, 34], "import": [3, 5, 19, 33, 34], "sever": [3, 5, 12, 23, 31, 32], "modul": 3, "includ": [3, 5, 6, 7, 23, 34], "field": [3, 5, 34], "from": [3, 5, 6, 7, 12, 19, 23, 33, 34], "type": [3, 5, 6, 9, 31], "option": [3, 5, 6, 11, 12, 20], "require_vers": [3, 5], "transform": [3, 5, 12, 33], "util": [3, 4, 5, 8, 34], "model_for_causal_lm_map": [3, 5], "trainingargu": [3, 5], "model_config_class": [3, 5], "i": [3, 5, 12, 18, 19, 31, 34], "assign": [3, 5], "list": [3, 5, 12, 23, 31, 34], "config": [3, 5, 33], "class": [3, 7], "model_typ": [3, 5], "tupl": [3, 5], "extract": [3, 5, 23], "page": [4, 34], "auto": [4, 5], "gener": [4, 5, 12, 19, 23, 32, 34], "document": 4, "lmflow": [4, 33], "interfac": [4, 8, 12, 13], "tunabl": [4, 8, 12, 13, 14, 18], "auto_model": [4, 8, 13], "base_model": [4, 8, 11, 13], "decoder_model": [4, 8, 12, 13], "hf_decoder_model": [4, 8, 13], "pipelin": [4, 8, 31, 33, 34], "auto_pipelin": [4, 8, 21, 33], "base_pipelin": [4, 8, 18, 19, 21, 22], "base_tun": [4, 8, 20, 21], "evalu": [4, 5, 8, 21, 31, 34], "inferenc": [4, 5, 8, 21, 31], "data_util": [4, 8, 24], "arg": [4, 6, 8, 9, 10, 11, 12, 16, 18, 20, 23, 33], "creat": [4, 6, 10, 11, 15, 17, 19, 34], "sphinx": 4, "autoapi": 4, "sourc": [5, 6, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 23, 25, 31, 34], "decor": 5, "paramet": [5, 6, 12, 19, 20, 22, 23, 34], "can": [5, 12, 31, 34], "configur": 5, "model_name_or_path": 5, "str": [5, 6, 12, 22, 23], "string": [5, 6, 12, 23], "repres": [5, 6, 12], "path": [5, 12, 33], "name": [5, 12, 16, 23], "pretrain": [5, 12, 34], "checkpoint": 5, "weight": [5, 19, 34], "initi": [5, 6, 7, 12, 19, 20, 22, 33], "If": [5, 23, 33, 34], "none": [5, 6, 12, 19, 23], "scratch": 5, "provid": [5, 10, 11, 12, 15, 17, 19, 31, 32, 34], "config_overrid": 5, "default": [5, 6, 12, 23], "set": [5, 12, 23, 31], "overrid": 5, "when": 5, "config_nam": 5, "differ": [5, 6, 7, 12], "tokenizer_nam": 5, "token": [5, 12, 33], "cache_dir": 5, "directori": [5, 19, 31], "where": [5, 31], "download": [5, 31], "huggingfac": [5, 6, 12], "co": 5, "store": 5, "use_fast_token": 5, "bool": [5, 23], "boolean": 5, "indic": [5, 31], "whether": 5, "fast": 5, "back": 5, "librari": 5, "model_revis": 5, "specif": [5, 34], "branch": 5, "tag": 5, "commit": 5, "id": [5, 12], "use_auth_token": 5, "run": [5, 19, 20, 31], "cli": 5, "login": 5, "necessari": 5, "privat": 5, "torch_dtyp": 5, "dtype": 5, "load": [5, 6, 7, 12, 19, 20, 22, 23], "under": [5, 31, 34], "pass": [5, 33, 34], "automat": [5, 9, 16], "deriv": 5, "": [5, 33, 34], "lora_model_path": 5, "use_lora": 5, "lora_r": 5, "int": [5, 12, 22, 23], "lora_alpha": 5, "lora_dropout": 5, "float": [5, 22], "__post_init__": 5, "languag": [5, 12, 19, 20, 34], "dataset_path": 5, "dataset_nam": 5, "valu": 5, "custom": [5, 31], "is_custom_dataset": 5, "data": [5, 19, 20, 23, 31, 34], "fals": 5, "customized_cache_dir": 5, "cach": 5, "dataset_config_nam": 5, "via": 5, "train_fil": 5, "input": [5, 12, 19, 22, 23, 31], "file": [5, 19, 23, 31, 33, 34], "text": [5, 12, 19, 20, 23, 31, 33], "validation_fil": 5, "perplex": 5, "max_train_sampl": 5, "an": [5, 10, 11, 15, 17, 34], "integ": 5, "maximum": [5, 20], "number": 5, "exampl": [5, 11, 23, 31, 34], "debug": 5, "quicker": 5, "truncat": 5, "max_eval_sampl": 5, "stream": 5, "enabl": 5, "mode": 5, "block_siz": 5, "sequenc": [5, 12], "length": [5, 12, 20, 23], "after": [5, 31], "block": [5, 20], "size": [5, 19], "also": [5, 11, 19, 34], "some": [5, 19, 34], "addit": 5, "further": [5, 34], "overwrite_cach": 5, "validation_split_percentag": 5, "preprocessing_num_work": 5, "disable_group_text": 5, "demo_example_in_prompt": 5, "explanation_in_prompt": 5, "keep_linebreak": 5, "prompt_structur": [5, 22], "function": [5, 11, 34], "help": [5, 34], "messag": 5, "each": [5, 31], "hint": 5, "metadata": 5, "inform": [5, 6, 19, 34], "about": [5, 34], "test_fil": 5, "finetunerargu": [5, 20], "base": [5, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 34], "adapt": [5, 12, 34], "evaluatorargu": [5, 19], "local_rank": 5, "For": [5, 31, 34], "distribut": 5, "random_shuffl": [5, 23], "use_wandb": [5, 19], "random_se": 5, "output_dir": 5, "mixed_precis": 5, "choic": [5, 23], "bf16": 5, "fp16": 5, "mix": 5, "precis": 5, "deepspe": [5, 12, 33], "json": [5, 6, 7, 23, 31, 33], "e": [5, 23, 34], "g": 5, "ds_config": [5, 12], "alreadi": 5, "dict": [5, 6], "answer_typ": [5, 19, 23], "inferencerargu": [5, 22], "pipeline_argument_map": 5, "autoargu": [5, 33], "choos": 5, "get_pipeline_args_class": [5, 33], "python": [6, 7, 34], "code": [6, 7], "method": [6, 7, 12, 19, 34], "manipul": [6, 7], "backend": [6, 7, 12], "hug": [6, 7, 31], "face": [6, 7], "dictionari": [6, 7, 19, 20], "map": [6, 7, 33], "retriev": [6, 7], "dataset_typ": 6, "text_onli": [6, 31], "text2text": [6, 32], "key_typ": 6, "key_inst": 6, "instanc": [6, 12, 19, 20, 31, 34], "data_arg": [6, 16, 19, 20, 22, 33], "kwarg": [6, 9, 10, 11, 12, 16, 18, 20], "object": [6, 19, 20, 22], "given": [6, 19, 20, 22], "requir": [6, 19, 20, 22, 34], "posit": [6, 12, 20, 34], "keyword": [6, 12, 20], "_check_data_typ": 6, "from_dict": 6, "dict_obj": 6, "return": [6, 12, 16, 19, 20, 22, 23], "format": [6, 32], "key_1": [6, 31], "value_1": [6, 31], "key_2": [6, 31], "2": [6, 31, 33, 34], "value_2": [6, 31], "self": 6, "to_dict": 6, "get_backend": 6, "get_backend_dataset": 6, "backend_dataset": 6, "get_data_arg": 6, "get_typ": 6, "internal_vers": 8, "__version__": [8, 25], "get": [9, 33], "correct": 9, "automodel": 9, "classmethod": [9, 16], "get_model": 9, "model_arg": [9, 12, 16, 19, 20, 22, 33], "basemodel": [10, 11], "abc": [10, 11, 15, 17], "helper": [10, 11, 15, 17], "standard": [10, 11, 15, 17], "wai": [10, 11, 15, 17, 31], "inherit": [10, 11, 15, 17], "one": [11, 33], "line": 11, "summari": 11, "program": [11, 23], "termin": 11, "period": 11, "leav": 11, "blank": 11, "rest": 11, "docstr": 11, "should": 11, "overal": [11, 12, 34], "descript": 11, "mai": 11, "brief": 11, "export": 11, "usag": 11, "typic": 11, "foo": 11, "classfoo": 11, "bar": 11, "functionbar": 11, "decodermodel": [11, 12], "call": 12, "hfdecodermodel": [12, 19], "which": [12, 18, 31, 34], "wrapper": 12, "around": 12, "ha": [12, 19, 31], "__init__": 12, "ar": [12, 31, 34], "fine": [12, 27, 34], "take": [12, 19], "tune_strategi": 12, "attent": 12, "mask": 12, "fed": 12, "support": [12, 32], "normal": 12, "allow": [12, 34], "howev": [12, 34], "strategi": 12, "yet": 12, "implement": 12, "conveni": [12, 34], "variou": [12, 31, 34], "nlp": 12, "classif": 12, "question": [12, 31], "answer": [12, 23, 31], "revis": 12, "etc": [12, 34], "configu": 12, "full": [12, 34], "tokenized_dataset": [12, 20, 33], "encod": [12, 19, 31], "union": 12, "perform": [12, 19, 20, 22, 34], "process": [12, 19, 20, 22, 33, 34], "output": [12, 19, 23, 31], "decod": [12, 19, 23, 31], "prompt": [12, 31, 34], "get_max_length": [12, 33], "max": 12, "accept": [12, 31], "term": 12, "get_token": 12, "get_backend_model": 12, "its": [16, 34], "pipeline_map": 16, "autopipelin": [16, 33], "design": [16, 34], "get_pipelin": [16, 33], "pipeline_nam": [16, 33], "pipeline_arg": [16, 33], "basepipelin": [17, 18, 19, 22], "basetun": [18, 20], "subclass": 18, "_check_if_tun": 18, "abstract": 18, "packag": [19, 32, 34], "constructor": 19, "three": [19, 31], "relat": [19, 34], "evaluator_arg": 19, "other": [19, 34], "two": 19, "create_dataload": [19, 22], "test": [19, 31, 34], "loader": 19, "iter": 19, "over": [19, 31], "mini": 19, "batch": [19, 23], "Then": 19, "write": 19, "log": 19, "consol": 19, "bias": 19, "true": [19, 23], "_match": 19, "predicted_answ": 19, "groundtruth": 19, "tunablemodel": [19, 20, 22, 33], "logger": 20, "finetuner_arg": 20, "group_text": [20, 33], "model_max_length": [20, 33], "group": [20, 33], "togeth": 20, "form": 20, "lm_dataset": [20, 33], "inferencer_arg": 22, "max_new_token": 22, "100": 22, "temperatur": 22, "output_dataset": 22, "random": 23, "seed": 23, "set_random_se": 23, "numpi": 23, "torch": 23, "cuda": 23, "load_data": 23, "file_nam": 23, "len": [23, 33], "batchliz": 23, "batch_siz": 23, "convert": 23, "dataload": 23, "shuffl": 23, "answer_extract": 23, "respons": [23, 34], "funtion": 23, "plain": 23, "b": 23, "c": 23, "d": 23, "mutipl": 23, "qa": 23, "we": [31, 32, 33, 34], "avail": [31, 34], "cd": 31, "sh": 31, "strongli": 31, "encourag": 31, "sinc": 31, "appli": [31, 34], "own": 31, "engin": 31, "techniqu": [31, 34], "As": 31, "long": 31, "follow": [31, 34], "below": [31, 34], "thei": 31, "our": [31, 32, 33, 34], "To": [31, 34], "specifi": 31, "path_to_dataset": 31, "data_1": 31, "data_2": 31, "another_data": 31, "current": 31, "onli": [31, 33, 34], "singl": 31, "shall": [31, 34], "have": [31, 34], "four": 31, "kei": 31, "key_3": 31, "3": [31, 34], "key_4": 31, "4": [31, 34], "value_3": 31, "correspond": 31, "interpret": 31, "most": 31, "common": [31, 34], "raw": 31, "sampl": 31, "Its": [31, 34], "sample_text_1": 31, "sample_text_2": 31, "sample_text_3": 31, "example_dataset": 31, "train_50": 31, "abov": 31, "mostli": 31, "pair": 31, "sample_input_1": 31, "sample_output_1": 31, "sample_input_2": 31, "sample_output_2": 31, "sample_input_3": 31, "sample_output_3": 31, "test_13": 31, "show": 32, "how": 32, "your": 32, "problem": 32, "detail": 32, "textonli": 32, "refer": [32, 34], "sy": 33, "hfargumentpars": 33, "tunable_model": 33, "def": 33, "main": [33, 34], "pars": 33, "pipelineargu": 33, "parser": 33, "argv": 33, "endswith": 33, "let": 33, "parse_json_fil": 33, "json_fil": 33, "o": 33, "abspath": 33, "els": 33, "parse_args_into_dataclass": 33, "todo": 33, "must": [33, 34], "done": 33, "main_process_first": 33, "desc": 33, "tuned_model": 33, "toolbox": 34, "larg": 34, "machin": 34, "learn": 34, "friendli": 34, "speedi": 34, "reliabl": 34, "access": 34, "entir": 34, "commun": 34, "backbon": 34, "llama": 34, "galactica": 34, "gpt": 34, "light": 34, "extrem": 34, "few": 34, "33b": 34, "25mb": 34, "storag": 34, "orient": 34, "compar": 34, "chatgpt": 34, "7b": 34, "open": 34, "whole": 34, "remark": 34, "achiev": 34, "foundat": 34, "expans": 34, "demonstr": 34, "except": 34, "capac": 34, "attain": 34, "human": 34, "like": 34, "intellig": 34, "surpass": 34, "convent": 34, "despit": 34, "grow": 34, "still": 34, "cater": 34, "while": 34, "maintain": 34, "ai": 34, "compet": 34, "pleas": 34, "introduc": 34, "lightweight": 34, "toolkit": 34, "thoughtfulli": 34, "easili": 34, "scalabl": 34, "tool": 34, "publicli": 34, "maxim": 34, "effect": 34, "thoroughli": 34, "make": 34, "github": 34, "goal": 34, "enhanc": 34, "profici": 34, "particular": 34, "medicin": 34, "mathemat": 34, "By": 34, "do": 34, "so": 34, "acquir": 34, "domain": 34, "better": 34, "target": 34, "subject": 34, "matter": 34, "medic": 34, "gain": 34, "knowledg": 34, "emphas": 34, "signific": 34, "pubmedqa": 34, "medmcqa": 34, "observ": 34, "improv": 34, "both": 34, "out": 34, "medqa": 34, "usml": 34, "averag": 34, "60": 34, "50": 34, "expert": 34, "78": 34, "87": 34, "90": 34, "85": 34, "instructgpt": 34, "175b": 34, "73": 34, "46": 34, "44": 34, "54": 34, "63": 34, "9": 34, "57": 34, "7": 34, "55": 34, "5": 34, "27": 34, "24": 34, "18": 34, "8": 34, "43": 34, "30": 34, "25": 34, "75": 34, "49": 34, "56": 34, "74": 34, "51": 34, "58": 34, "moreov": 34, "mmlu": 34, "verifi": 34, "robust": 34, "anatomi": 34, "clinic": 34, "colleg": 34, "biologi": 34, "genet": 34, "profession": 34, "39": 34, "40": 34, "32": 34, "36": 34, "30b": 34, "26": 34, "23": 34, "120b": 34, "59": 34, "68": 34, "6": 34, "opt": 34, "21": 34, "35": 34, "bloom": 34, "176b": 34, "37": 34, "29": 34, "gopher": 34, "280b": 34, "67": 34, "70": 34, "69": 34, "64": 34, "gpt3": 34, "72": 34, "61": 34, "65": 34, "66": 34, "them": 34, "natur": 34, "command": 34, "neg": 34, "constraint": 34, "element": 34, "commonli": 34, "found": 34, "abil": 34, "well": 34, "multipl": 34, "more": 34, "new": 34, "unseen": 34, "teach": 34, "understand": 34, "incorpor": 34, "cue": 34, "relev": 34, "hand": 34, "power": 34, "wide": 34, "area": 34, "approach": 34, "unlock": 34, "level": 34, "product": 34, "rang": 34, "applic": 34, "save": 34, "jsonl": 34, "git": 34, "clone": 34, "http": 34, "com": 34, "optimalscal": 34, "conda": 34, "n": 34, "y": 34, "activ": 34, "mpi4pi": 34, "pip": 34, "prepar": 34, "readm": 34, "misc": 34, "author": 34, "kashun": 34, "titl": 34, "year": 34, "publish": 34, "journal": 34, "repositori": 34, "howpublish": 34, "url": 34, "io": 34, "aim": 34, "streamlin": 34, "serv": 34, "intend": 34, "note": 34, "li": 34, "sole": 34, "doe": 34, "guarante": 34, "accuraci": 34, "complet": 34, "legal": 34, "compon": 34, "awar": 34, "assum": 34, "all": 34, "risk": 34, "liabil": 34, "associ": 34, "obtain": 34, "commerci": 34, "technic": 34, "advic": 34, "befor": 34, "held": 34, "ani": 34, "direct": 34, "indirect": 34, "special": 34, "incident": 34, "consequenti": 34, "damag": 34, "result": 34, "improp": 34, "crucial": 34, "highlight": 34, "probabilist": 34, "directli": 34, "therefor": 34, "seek": 34, "reli": 34, "outcom": 34, "account": 34, "relianc": 34, "you": 34, "need": 34, "submit": 34, "issu": 34, "index": 34, "search": 34}, "objects": {"": [[8, 0, 0, "-", "lmflow"]], "lmflow": [[8, 1, 1, "", "__version__"], [5, 0, 0, "-", "args"], [7, 0, 0, "-", "datasets"], [8, 1, 1, "", "internal_version"], [13, 0, 0, "-", "models"], [21, 0, 0, "-", "pipeline"], [24, 0, 0, "-", "utils"], [25, 0, 0, "-", "version"]], "lmflow.args": [[5, 2, 1, "", "AutoArguments"], [5, 2, 1, "", "DatasetArguments"], [5, 2, 1, "", "EvaluatorArguments"], [5, 2, 1, "", "FinetunerArguments"], [5, 2, 1, "", "InferencerArguments"], [5, 1, 1, "", "MODEL_CONFIG_CLASSES"], [5, 1, 1, "", "MODEL_TYPES"], [5, 2, 1, "", "ModelArguments"], [5, 1, 1, "", "PIPELINE_ARGUMENT_MAPPING"]], "lmflow.args.AutoArguments": [[5, 3, 1, "", "get_pipeline_args_class"]], "lmflow.args.DatasetArguments": [[5, 3, 1, "", "__post_init__"], [5, 4, 1, "", "block_size"], [5, 4, 1, "", "customized_cache_dir"], [5, 4, 1, "", "dataset_config_name"], [5, 4, 1, "", "dataset_name"], [5, 4, 1, "", "dataset_path"], [5, 4, 1, "", "disable_group_texts"], [5, 4, 1, "", "is_custom_dataset"], [5, 4, 1, "", "keep_linebreaks"], [5, 4, 1, "", "max_eval_samples"], [5, 4, 1, "", "max_train_samples"], [5, 4, 1, "", "overwrite_cache"], [5, 4, 1, "", "preprocessing_num_workers"], [5, 4, 1, "", "streaming"], [5, 4, 1, "", "test_file"], [5, 4, 1, "", "train_file"], [5, 4, 1, "", "validation_file"], [5, 4, 1, "", "validation_split_percentage"]], "lmflow.args.EvaluatorArguments": [[5, 4, 1, "", "answer_type"], [5, 4, 1, "", "deepspeed"], [5, 4, 1, "", "local_rank"], [5, 4, 1, "", "mixed_precision"], [5, 4, 1, "", "output_dir"], [5, 4, 1, "", "prompt_structure"], [5, 4, 1, "", "random_seed"], [5, 4, 1, "", "random_shuffle"], [5, 4, 1, "", "use_wandb"]], "lmflow.args.InferencerArguments": [[5, 4, 1, "", "deepspeed"], [5, 4, 1, "", "local_rank"], [5, 4, 1, "", "mixed_precision"], [5, 4, 1, "", "random_seed"]], "lmflow.args.ModelArguments": [[5, 3, 1, "", "__post_init__"], [5, 4, 1, "", "cache_dir"], [5, 4, 1, "", "config_name"], [5, 4, 1, "", "config_overrides"], [5, 4, 1, "", "lora_alpha"], [5, 4, 1, "", "lora_dropout"], [5, 4, 1, "", "lora_model_path"], [5, 4, 1, "", "lora_r"], [5, 4, 1, "", "model_name_or_path"], [5, 4, 1, "", "model_revision"], [5, 4, 1, "", "model_type"], [5, 4, 1, "", "tokenizer_name"], [5, 4, 1, "", "torch_dtype"], [5, 4, 1, "", "use_auth_token"], [5, 4, 1, "", "use_fast_tokenizer"], [5, 4, 1, "", "use_lora"]], "lmflow.datasets": [[6, 0, 0, "-", "dataset"]], "lmflow.datasets.dataset": [[6, 1, 1, "", "DATASET_TYPES"], [6, 2, 1, "", "Dataset"], [6, 1, 1, "", "KEY_INSTANCES"], [6, 1, 1, "", "KEY_TYPE"]], "lmflow.datasets.dataset.Dataset": [[6, 3, 1, "", "_check_data_type"], [6, 3, 1, "", "from_dict"], [6, 3, 1, "", "get_backend"], [6, 3, 1, "", "get_backend_dataset"], [6, 3, 1, "", "get_data_args"], [6, 3, 1, "", "get_type"], [6, 3, 1, "", "map"], [6, 3, 1, "", "to_dict"]], "lmflow.models": [[9, 0, 0, "-", "auto_model"], [10, 0, 0, "-", "base_model"], [11, 0, 0, "-", "decoder_model"], [12, 0, 0, "-", "hf_decoder_model"], [14, 0, 0, "-", "interfaces"]], "lmflow.models.auto_model": [[9, 2, 1, "", "AutoModel"]], "lmflow.models.auto_model.AutoModel": [[9, 3, 1, "", "get_model"]], "lmflow.models.base_model": [[10, 2, 1, "", "BaseModel"]], "lmflow.models.decoder_model": [[11, 2, 1, "", "DecoderModel"]], "lmflow.models.hf_decoder_model": [[12, 2, 1, "", "HFDecoderModel"]], "lmflow.models.hf_decoder_model.HFDecoderModel": [[12, 3, 1, "", "decode"], [12, 3, 1, "", "encode"], [12, 3, 1, "", "get_backend_model"], [12, 3, 1, "", "get_max_length"], [12, 3, 1, "", "get_tokenizer"], [12, 3, 1, "", "inference"], [12, 3, 1, "", "tokenize"]], "lmflow.models.interfaces": [[15, 0, 0, "-", "tunable"]], "lmflow.models.interfaces.tunable": [[15, 2, 1, "", "Tunable"]], "lmflow.pipeline": [[16, 0, 0, "-", "auto_pipeline"], [17, 0, 0, "-", "base_pipeline"], [18, 0, 0, "-", "base_tuner"], [19, 0, 0, "-", "evaluator"], [20, 0, 0, "-", "finetuner"], [22, 0, 0, "-", "inferencer"]], "lmflow.pipeline.auto_pipeline": [[16, 2, 1, "", "AutoPipeline"], [16, 1, 1, "", "PIPELINE_MAPPING"]], "lmflow.pipeline.auto_pipeline.AutoPipeline": [[16, 3, 1, "", "get_pipeline"]], "lmflow.pipeline.base_pipeline": [[17, 2, 1, "", "BasePipeline"]], "lmflow.pipeline.base_tuner": [[18, 2, 1, "", "BaseTuner"]], "lmflow.pipeline.base_tuner.BaseTuner": [[18, 3, 1, "", "_check_if_tunable"], [18, 3, 1, "", "tune"]], "lmflow.pipeline.evaluator": [[19, 2, 1, "", "Evaluator"]], "lmflow.pipeline.evaluator.Evaluator": [[19, 3, 1, "", "_match"], [19, 3, 1, "", "create_dataloader"], [19, 3, 1, "", "evaluate"]], "lmflow.pipeline.finetuner": [[20, 2, 1, "", "Finetuner"], [20, 1, 1, "", "logger"]], "lmflow.pipeline.finetuner.Finetuner": [[20, 3, 1, "", "group_text"], [20, 3, 1, "", "tune"]], "lmflow.pipeline.inferencer": [[22, 2, 1, "", "Inferencer"]], "lmflow.pipeline.inferencer.Inferencer": [[22, 3, 1, "", "create_dataloader"], [22, 3, 1, "", "inference"]], "lmflow.utils": [[23, 0, 0, "-", "data_utils"]], "lmflow.utils.data_utils": [[23, 5, 1, "", "answer_extraction"], [23, 5, 1, "", "batchlize"], [23, 5, 1, "", "load_data"], [23, 5, 1, "", "set_random_seed"]], "lmflow.version": [[25, 1, 1, "", "__version__"]]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:class", "3": "py:method", "4": "py:attribute", "5": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"]}, "titleterms": {"contributor": 0, "changelog": 1, "version": [1, 25], "0": 1, "1": 1, "mar": 1, "28": 1, "2023": 1, "about": 2, "lmflow": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 34], "arg": [3, 5], "api": 4, "refer": 4, "modul": [5, 6, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 23, 25], "content": [5, 6, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22, 23, 25, 34], "class": [5, 6, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 22], "attribut": [5, 6, 16, 20], "dataset": [6, 7, 31], "submodul": [7, 8, 13, 14, 21, 24], "subpackag": [8, 13], "packag": 8, "model": [9, 10, 11, 12, 13, 14, 15, 27, 29], "auto_model": 9, "base_model": 10, "decoder_model": 11, "hf_decoder_model": 12, "interfac": [14, 15], "tunabl": 15, "pipelin": [16, 17, 18, 19, 20, 21, 22], "auto_pipelin": 16, "base_pipelin": 17, "base_tun": 18, "evalu": 19, "finetun": [20, 32, 33], "inferenc": 22, "util": [23, 24], "data_util": 23, "function": 23, "data": [26, 27, 32], "document": 27, "prepar": [27, 32], "tune": [27, 30, 34], "infer": [27, 28, 32], "fine": 30, "format": 31, "gener": 31, "support": [31, 34], "detail": 31, "textonli": 31, "text2text": 31, "exampl": 32, "introduct": 34, "featur": 34, "task": 34, "instruct": 34, "instal": 34, "checkpoint": 34, "citat": 34, "disclaim": 34, "indic": 34, "tabl": 34}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Contributors": [[0, "contributors"]], "Changelog": [[1, "changelog"]], "Version 0.0.1 (Mar 28, 2023)": [[1, "version-0-0-1-mar-28-2023"]], "About": [[2, "about"]], "lmflow.args": [[3, "module-lmflow.args"], [5, "module-lmflow.args"]], "API Reference": [[4, "api-reference"]], "Module Contents": [[5, "module-contents"], [6, "module-contents"], [9, "module-contents"], [10, "module-contents"], [11, "module-contents"], [12, "module-contents"], [15, "module-contents"], [16, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [22, "module-contents"], [23, "module-contents"], [25, "module-contents"]], "Classes": [[5, "classes"], [6, "classes"], [9, "classes"], [10, "classes"], [11, "classes"], [12, "classes"], [15, "classes"], [16, "classes"], [17, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [22, "classes"]], "Attributes": [[5, "attributes"], [6, "attributes"], [16, "attributes"], [20, "attributes"]], "lmflow.datasets.dataset": [[6, "module-lmflow.datasets.dataset"]], "lmflow.datasets": [[7, "module-lmflow.datasets"]], "Submodules": [[7, "submodules"], [8, "submodules"], [13, "submodules"], [14, "submodules"], [21, "submodules"], [24, "submodules"]], "lmflow": [[8, "module-lmflow"]], "Subpackages": [[8, "subpackages"], [13, "subpackages"]], "Package Contents": [[8, "package-contents"]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model"]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model"]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model"]], "lmflow.models.hf_decoder_model": [[12, "module-lmflow.models.hf_decoder_model"]], "lmflow.models": [[13, "module-lmflow.models"]], "lmflow.models.interfaces": [[14, "module-lmflow.models.interfaces"]], "lmflow.models.interfaces.tunable": [[15, "module-lmflow.models.interfaces.tunable"]], "lmflow.pipeline.auto_pipeline": [[16, "module-lmflow.pipeline.auto_pipeline"]], "lmflow.pipeline.base_pipeline": [[17, "module-lmflow.pipeline.base_pipeline"]], "lmflow.pipeline.base_tuner": [[18, "module-lmflow.pipeline.base_tuner"]], "lmflow.pipeline.evaluator": [[19, "module-lmflow.pipeline.evaluator"]], "lmflow.pipeline.finetuner": [[20, "module-lmflow.pipeline.finetuner"]], "lmflow.pipeline": [[21, "module-lmflow.pipeline"]], "lmflow.pipeline.inferencer": [[22, "module-lmflow.pipeline.inferencer"]], "lmflow.utils.data_utils": [[23, "module-lmflow.utils.data_utils"]], "Functions": [[23, "functions"]], "lmflow.utils": [[24, "module-lmflow.utils"]], "lmflow.version": [[25, "module-lmflow.version"]], "Data": [[26, "data"]], "Documentation": [[27, "documentation"]], "Data and Model Preparation": [[27, "data-and-model-preparation"]], "Model Tuning": [[27, "model-tuning"]], "Model Inference": [[27, "model-inference"]], "Inference": [[28, "inference"], [32, "inference"]], "Model": [[29, "model"]], "Fine-tuning": [[30, "fine-tuning"]], "Dataset": [[31, "dataset"]], "Dataset Format in General": [[31, "dataset-format-in-general"]], "Supported Dataset and Detailed Formats": [[31, "supported-dataset-and-detailed-formats"]], "TextOnly": [[31, "textonly"]], "Text2Text": [[31, "text2text"]], "Examples": [[32, "examples"]], "Data preparation": [[32, "data-preparation"]], "Finetuning": [[32, "finetuning"]], "Finetune": [[33, "finetune"]], "LMFlow": [[34, "lmflow"]], "Introduction": [[34, "introduction"]], "Features": [[34, "features"]], "Task Tuning": [[34, "task-tuning"]], "Instruction Tuning": [[34, "instruction-tuning"]], "Installation": [[34, "installation"]], "Checkpoints": [[34, "checkpoints"]], "Content": [[34, "content"]], "Citation": [[34, "citation"]], "Disclaimer": [[34, "disclaimer"]], "Support": [[34, "support"]], "Indices and tables": [[34, "indices-and-tables"]]}, "indexentries": {"lmflow.args": [[3, "module-lmflow.args"], [5, "module-lmflow.args"]], "module": [[3, "module-lmflow.args"], [5, "module-lmflow.args"], [6, "module-lmflow.datasets.dataset"], [7, "module-lmflow.datasets"], [8, "module-lmflow"], [9, "module-lmflow.models.auto_model"], [10, "module-lmflow.models.base_model"], [11, "module-lmflow.models.decoder_model"], [12, "module-lmflow.models.hf_decoder_model"], [13, "module-lmflow.models"], [14, "module-lmflow.models.interfaces"], [15, "module-lmflow.models.interfaces.tunable"], [16, "module-lmflow.pipeline.auto_pipeline"], [17, "module-lmflow.pipeline.base_pipeline"], [18, "module-lmflow.pipeline.base_tuner"], [19, "module-lmflow.pipeline.evaluator"], [20, "module-lmflow.pipeline.finetuner"], [21, "module-lmflow.pipeline"], [22, "module-lmflow.pipeline.inferencer"], [23, "module-lmflow.utils.data_utils"], [24, "module-lmflow.utils"], [25, "module-lmflow.version"]], "autoarguments (class in lmflow.args)": [[5, "lmflow.args.AutoArguments"]], "datasetarguments (class in lmflow.args)": [[5, "lmflow.args.DatasetArguments"]], "evaluatorarguments (class in lmflow.args)": [[5, "lmflow.args.EvaluatorArguments"]], "finetunerarguments (class in lmflow.args)": [[5, "lmflow.args.FinetunerArguments"]], "inferencerarguments (class in lmflow.args)": [[5, "lmflow.args.InferencerArguments"]], "model_config_classes (in module lmflow.args)": [[5, "lmflow.args.MODEL_CONFIG_CLASSES"]], "model_types (in module lmflow.args)": [[5, "lmflow.args.MODEL_TYPES"]], "modelarguments (class in lmflow.args)": [[5, "lmflow.args.ModelArguments"]], "pipeline_argument_mapping (in module lmflow.args)": [[5, "lmflow.args.PIPELINE_ARGUMENT_MAPPING"]], "__post_init__() (lmflow.args.datasetarguments method)": [[5, "lmflow.args.DatasetArguments.__post_init__"]], "__post_init__() (lmflow.args.modelarguments method)": [[5, "lmflow.args.ModelArguments.__post_init__"]], "answer_type (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.answer_type"]], "block_size (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.block_size"]], "cache_dir (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.cache_dir"]], "config_name (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.config_name"]], "config_overrides (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.config_overrides"]], "customized_cache_dir (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.customized_cache_dir"]], "dataset_config_name (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_config_name"]], "dataset_name (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_name"]], "dataset_path (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_path"]], "deepspeed (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.deepspeed"]], "deepspeed (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.deepspeed"]], "disable_group_texts (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.disable_group_texts"]], "get_pipeline_args_class() (lmflow.args.autoarguments method)": [[5, "lmflow.args.AutoArguments.get_pipeline_args_class"]], "is_custom_dataset (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.is_custom_dataset"]], "keep_linebreaks (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.keep_linebreaks"]], "local_rank (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.local_rank"]], "local_rank (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.local_rank"]], "lora_alpha (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_alpha"]], "lora_dropout (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_dropout"]], "lora_model_path (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_model_path"]], "lora_r (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_r"]], "max_eval_samples (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.max_eval_samples"]], "max_train_samples (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.max_train_samples"]], "mixed_precision (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.mixed_precision"]], "mixed_precision (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.mixed_precision"]], "model_name_or_path (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_name_or_path"]], "model_revision (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_revision"]], "model_type (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_type"]], "output_dir (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.output_dir"]], "overwrite_cache (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.overwrite_cache"]], "preprocessing_num_workers (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.preprocessing_num_workers"]], "prompt_structure (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.prompt_structure"]], "random_seed (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.random_seed"]], "random_seed (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.random_seed"]], "random_shuffle (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.random_shuffle"]], "streaming (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.streaming"]], "test_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.test_file"]], "tokenizer_name (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.tokenizer_name"]], "torch_dtype (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.torch_dtype"]], "train_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.train_file"]], "use_auth_token (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_auth_token"]], "use_fast_tokenizer (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_fast_tokenizer"]], "use_lora (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_lora"]], "use_wandb (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.use_wandb"]], "validation_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.validation_file"]], "validation_split_percentage (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.validation_split_percentage"]], "dataset_types (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.DATASET_TYPES"]], "dataset (class in lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.Dataset"]], "key_instances (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.KEY_INSTANCES"]], "key_type (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.KEY_TYPE"]], "_check_data_type() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset._check_data_type"]], "from_dict() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.from_dict"]], "get_backend() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_backend"]], "get_backend_dataset() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_backend_dataset"]], "get_data_args() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_data_args"]], "get_type() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_type"]], "lmflow.datasets.dataset": [[6, "module-lmflow.datasets.dataset"]], "map() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.map"]], "to_dict() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.to_dict"]], "lmflow.datasets": [[7, "module-lmflow.datasets"]], "__version__ (in module lmflow)": [[8, "lmflow.__version__"]], "internal_version (in module lmflow)": [[8, "lmflow.internal_version"]], "lmflow": [[8, "module-lmflow"]], "automodel (class in lmflow.models.auto_model)": [[9, "lmflow.models.auto_model.AutoModel"]], "get_model() (lmflow.models.auto_model.automodel class method)": [[9, "lmflow.models.auto_model.AutoModel.get_model"]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model"]], "basemodel (class in lmflow.models.base_model)": [[10, "lmflow.models.base_model.BaseModel"]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model"]], "decodermodel (class in lmflow.models.decoder_model)": [[11, "lmflow.models.decoder_model.DecoderModel"]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model"]], "hfdecodermodel (class in lmflow.models.hf_decoder_model)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel"]], "decode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.decode"]], "encode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.encode"]], "get_backend_model() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.get_backend_model"]], "get_max_length() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.get_max_length"]], "get_tokenizer() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.get_tokenizer"]], "inference() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.inference"]], "lmflow.models.hf_decoder_model": [[12, "module-lmflow.models.hf_decoder_model"]], "tokenize() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[12, "lmflow.models.hf_decoder_model.HFDecoderModel.tokenize"]], "lmflow.models": [[13, "module-lmflow.models"]], "lmflow.models.interfaces": [[14, "module-lmflow.models.interfaces"]], "tunable (class in lmflow.models.interfaces.tunable)": [[15, "lmflow.models.interfaces.tunable.Tunable"]], "lmflow.models.interfaces.tunable": [[15, "module-lmflow.models.interfaces.tunable"]], "autopipeline (class in lmflow.pipeline.auto_pipeline)": [[16, "lmflow.pipeline.auto_pipeline.AutoPipeline"]], "pipeline_mapping (in module lmflow.pipeline.auto_pipeline)": [[16, "lmflow.pipeline.auto_pipeline.PIPELINE_MAPPING"]], "get_pipeline() (lmflow.pipeline.auto_pipeline.autopipeline class method)": [[16, "lmflow.pipeline.auto_pipeline.AutoPipeline.get_pipeline"]], "lmflow.pipeline.auto_pipeline": [[16, "module-lmflow.pipeline.auto_pipeline"]], "basepipeline (class in lmflow.pipeline.base_pipeline)": [[17, "lmflow.pipeline.base_pipeline.BasePipeline"]], "lmflow.pipeline.base_pipeline": [[17, "module-lmflow.pipeline.base_pipeline"]], "basetuner (class in lmflow.pipeline.base_tuner)": [[18, "lmflow.pipeline.base_tuner.BaseTuner"]], "_check_if_tunable() (lmflow.pipeline.base_tuner.basetuner method)": [[18, "lmflow.pipeline.base_tuner.BaseTuner._check_if_tunable"]], "lmflow.pipeline.base_tuner": [[18, "module-lmflow.pipeline.base_tuner"]], "tune() (lmflow.pipeline.base_tuner.basetuner method)": [[18, "lmflow.pipeline.base_tuner.BaseTuner.tune"]], "evaluator (class in lmflow.pipeline.evaluator)": [[19, "lmflow.pipeline.evaluator.Evaluator"]], "_match() (lmflow.pipeline.evaluator.evaluator method)": [[19, "lmflow.pipeline.evaluator.Evaluator._match"]], "create_dataloader() (lmflow.pipeline.evaluator.evaluator method)": [[19, "lmflow.pipeline.evaluator.Evaluator.create_dataloader"]], "evaluate() (lmflow.pipeline.evaluator.evaluator method)": [[19, "lmflow.pipeline.evaluator.Evaluator.evaluate"]], "lmflow.pipeline.evaluator": [[19, "module-lmflow.pipeline.evaluator"]], "finetuner (class in lmflow.pipeline.finetuner)": [[20, "lmflow.pipeline.finetuner.Finetuner"]], "group_text() (lmflow.pipeline.finetuner.finetuner method)": [[20, "lmflow.pipeline.finetuner.Finetuner.group_text"]], "lmflow.pipeline.finetuner": [[20, "module-lmflow.pipeline.finetuner"]], "logger (in module lmflow.pipeline.finetuner)": [[20, "lmflow.pipeline.finetuner.logger"]], "tune() (lmflow.pipeline.finetuner.finetuner method)": [[20, "lmflow.pipeline.finetuner.Finetuner.tune"]], "lmflow.pipeline": [[21, "module-lmflow.pipeline"]], "inferencer (class in lmflow.pipeline.inferencer)": [[22, "lmflow.pipeline.inferencer.Inferencer"]], "create_dataloader() (lmflow.pipeline.inferencer.inferencer method)": [[22, "lmflow.pipeline.inferencer.Inferencer.create_dataloader"]], "inference() (lmflow.pipeline.inferencer.inferencer method)": [[22, "lmflow.pipeline.inferencer.Inferencer.inference"]], "lmflow.pipeline.inferencer": [[22, "module-lmflow.pipeline.inferencer"]], "answer_extraction() (in module lmflow.utils.data_utils)": [[23, "lmflow.utils.data_utils.answer_extraction"]], "batchlize() (in module lmflow.utils.data_utils)": [[23, "lmflow.utils.data_utils.batchlize"]], "lmflow.utils.data_utils": [[23, "module-lmflow.utils.data_utils"]], "load_data() (in module lmflow.utils.data_utils)": [[23, "lmflow.utils.data_utils.load_data"]], "set_random_seed() (in module lmflow.utils.data_utils)": [[23, "lmflow.utils.data_utils.set_random_seed"]], "lmflow.utils": [[24, "module-lmflow.utils"]], "__version__ (in module lmflow.version)": [[25, "lmflow.version.__version__"]], "lmflow.version": [[25, "module-lmflow.version"]]}})